{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Create the Python Script\n",
    "\n",
    "In the cell below, you will need to complete the Python script and run the cell to generate the file using the magic `%%writefile` command. Your main task is to complete the following methods for the `PersonDetect` class:\n",
    "* `load_model`\n",
    "* `predict`\n",
    "* `draw_outputs`\n",
    "* `preprocess_outputs`\n",
    "* `preprocess_inputs`\n",
    "\n",
    "For your reference, here are all the arguments used for the argument parser in the command line:\n",
    "* `--model`:  The file path of the pre-trained IR model, which has been pre-processed using the model optimizer. There is automated support built in this argument to support both FP32 and FP16 models targeting different hardware.\n",
    "* `--device`: The type of hardware you want to load the model on (CPU, GPU, MYRIAD, HETERO:FPGA,CPU)\n",
    "* `--video`: The file path of the input video.\n",
    "* `--output_path`: The location where the output stats and video file with inference needs to be stored (results/[device]).\n",
    "* `--max_people`: The max number of people in queue before directing a person to another queue.\n",
    "* `--threshold`: The probability threshold value for the person detection. Optional arg; default value is 0.60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile person_detect.py\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "class Queue:\n",
    "    '''\n",
    "    Class for dealing with queues\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.queues=[]\n",
    "\n",
    "    def add_queue(self, points):\n",
    "        self.queues.append(points)\n",
    "\n",
    "    def get_queues(self, image):\n",
    "        for q in self.queues:\n",
    "            x_min, y_min, x_max, y_max=q\n",
    "            frame=image[y_min:y_max, x_min:x_max]\n",
    "            yield frame\n",
    "    \n",
    "    def check_coords(self, coords):\n",
    "        d={k+1:0 for k in range(len(self.queues))}\n",
    "        for coord in coords:\n",
    "            for i, q in enumerate(self.queues):\n",
    "                if coord[0]>q[0] and coord[2]<q[2]:\n",
    "                    d[i+1]+=1\n",
    "        return d\n",
    "\n",
    "\n",
    "class PersonDetect:\n",
    "    '''\n",
    "    Class for the Person Detection Model.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name, device, threshold=0.60):\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "        self.threshold=threshold\n",
    "\n",
    "        try:\n",
    "            self.model=IENetwork(self.model_structure, self.model_weights)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Could not Initialise the network. Have you enterred the correct model path?\")\n",
    "\n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape\n",
    "        print(\"Model initialized\")\n",
    "\n",
    "    def load_model(self, device=\"CPU\", cpu_extension=None):\n",
    "        '''\n",
    "        TODO: This method needs to be completed by you\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        Load the model given IR files.\n",
    "        Defaults to CPU as device for use in the workspace.\n",
    "        Synchronous requests made within.\n",
    "        '''\n",
    "        #model_xml = model\n",
    "        #model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "\n",
    "        # Initialize the plugin\n",
    "        self.plugin = IECore()\n",
    "\n",
    "        # Add a CPU extension, if applicable\n",
    "        if cpu_extension and \"CPU\" in device:\n",
    "            self.plugin.add_extension(cpu_extension, device)\n",
    "\n",
    "        # Read the IR as a IENetwork\n",
    "        self.network = IENetwork(model=self.model_structure, weights=self.model_weights)\n",
    "        print(\"IENetwork created\")\n",
    "\n",
    "        # Load the IENetwork into the plugin\n",
    "        self.exec_network = self.plugin.load_network(self.network, device)\n",
    "        print(\"IENetwork loaded to plugin\")\n",
    "\n",
    "        # Get the input layer\n",
    "        self.input_blob = next(iter(self.network.inputs))\n",
    "        self.output_blob = next(iter(self.network.outputs))\n",
    "        return\n",
    "   \n",
    "\n",
    "    def predict(self, image):\n",
    "        '''\n",
    "        TODO: This method needs to be completed by you\n",
    "        '''\n",
    "        #p_frame = preprocessing(image, height, width)\n",
    "        p_frame = self.preprocess_input(self, image)\n",
    "\n",
    "\n",
    "\n",
    "        #def exec_net(self, net_inputs):\n",
    "        ### TODO: Start an asynchronous request ###\n",
    "        '''\n",
    "        Makes an asynchronous inference request, given an input image.\n",
    "        '''\n",
    "        input_dict = {self.input_name: p_frame}\n",
    "        result = self.exec_network.start_async(request_id=0, inputs=input_dict)\n",
    "        result = result['detection_out']\n",
    "        result = self.preprocess_outputs(result)\n",
    "        #self.exec_network.start_async(request_id=0, inputs={self.input_blob: image})\n",
    "        #def get_output(self):\n",
    "        ### TODO: Extract and return the output results\n",
    "        '''\n",
    "        Returns a list of the results for the output layer of the network.\n",
    "        '''\n",
    "        coordinates, out_frame = self.draw_outputs(result, p_frame)\n",
    "        return coordinates, out_frame\n",
    "    \n",
    "\n",
    "    \n",
    "    def draw_outputs(self, coords, image):\n",
    "        '''\n",
    "        TODO: This method needs to be completed by you\n",
    "        '''\n",
    "        width = int(image.shape[1]) \n",
    "        height = int(image.shape[0])\n",
    "        detections = []\n",
    "        \n",
    "        for box in coords[0][0]:\n",
    "            if conf >= self.threshold:\n",
    "                xmin = int(box[3] * width)\n",
    "                ymin = int(box[4] * height)\n",
    "                xmax = int(box[5] * width)\n",
    "                ymax = int(box[6] * height)\n",
    "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 0, 255), 1)\n",
    "        return coords, image                \n",
    "\n",
    "\n",
    "        \n",
    "    def preprocess_outputs(self, outputs):\n",
    "        '''\n",
    "        TODO: This method needs to be completed by you\n",
    "        '''\n",
    "        output = np.squeeze(outputs)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def preprocess_input(self, image):\n",
    "        '''\n",
    "        TODO: This method needs to be completed by you\n",
    "        '''\n",
    "        try:\n",
    "            n, c, height, width = self.input_shape\n",
    "            input_img = np.copy(image)\n",
    "            input_img=cv2.resize(image, (width, height))\n",
    "            input_img = input_img.transpose(2,0,1)\n",
    "            input_img = input_img.reshape((n, c, height, width))\n",
    "        except Exception as e:\n",
    "            print('Preprocess inputs error: ',e)\n",
    "        return input_img\n",
    "    \n",
    "\n",
    "\n",
    "def main(args):\n",
    "    model=args.model\n",
    "    device=args.device\n",
    "    video_file=args.video\n",
    "    max_people=args.max_people\n",
    "    threshold=args.threshold\n",
    "    output_path=args.output_path\n",
    "\n",
    "    start_model_load_time=time.time()\n",
    "    pd= PersonDetect(model, device, threshold)\n",
    "    pd.load_model()\n",
    "    total_model_load_time = time.time() - start_model_load_time\n",
    "\n",
    "    queue=Queue()\n",
    "    \n",
    "    try:\n",
    "        queue_param=np.load(args.queue_param)\n",
    "        for q in queue_param:\n",
    "            queue.add_queue(q)\n",
    "    except:\n",
    "        print(\"error loading queue param file\")\n",
    "\n",
    "    try:\n",
    "        cap=cv2.VideoCapture(video_file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Cannot locate video file: \"+ video_file)\n",
    "    except Exception as e:\n",
    "        print(\"Something else went wrong with the video file: \", e)\n",
    "    \n",
    "    initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out_video = cv2.VideoWriter(os.path.join(output_path, 'output_video.mp4'), cv2.VideoWriter_fourcc(*'avc1'), fps, (initial_w, initial_h), True)\n",
    "    \n",
    "    counter=0\n",
    "    start_inference_time=time.time()\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame=cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            counter+=1\n",
    "            \n",
    "            coords, image= pd.predict(frame)\n",
    "            num_people= queue.check_coords(coords)\n",
    "            print(f\"Total People in frame = {len(coords)}\")\n",
    "            print(f\"Number of people in queue = {num_people}\")\n",
    "            out_text=\"\"\n",
    "            y_pixel=25\n",
    "            \n",
    "            for k, v in num_people.items():\n",
    "                out_text += f\"No. of People in Queue {k} is {v} \"\n",
    "                if v >= int(max_people):\n",
    "                    out_text += f\" Queue full; Please move to next Queue \"\n",
    "                cv2.putText(image, out_text, (15, y_pixel), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                out_text=\"\"\n",
    "                y_pixel+=40\n",
    "            out_video.write(image)\n",
    "            \n",
    "        total_time=time.time()-start_inference_time\n",
    "        total_inference_time=round(total_time, 1)\n",
    "        fps=counter/total_inference_time\n",
    "\n",
    "        with open(os.path.join(output_path, 'stats.txt'), 'w') as f:\n",
    "            f.write(str(total_inference_time)+'\\n')\n",
    "            f.write(str(fps)+'\\n')\n",
    "            f.write(str(total_model_load_time)+'\\n')\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(\"Could not run Inference: \", e)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', required=True)\n",
    "    parser.add_argument('--device', default='CPU')\n",
    "    parser.add_argument('--video', default=None)\n",
    "    parser.add_argument('--queue_param', default=None)\n",
    "    parser.add_argument('--output_path', default='/results')\n",
    "    parser.add_argument('--max_people', default=2)\n",
    "    parser.add_argument('--threshold', default=0.60)\n",
    "    \n",
    "    args=parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "Now that you've run the above cell and created your Python script, you will create your job submission shell script in the next workspace.\n",
    "\n",
    "**Note**: As a reminder, if you need to make any changes to the Python script, you can come back to this workspace to edit and run the above cell to overwrite the file with your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"data/models/intel/person-detection-retail-0013/FP32/person-detection-retail-0013\"\n",
    "device=\"CPU\"\n",
    "video_file=\"/data/resources/manufacturing.mp4\"\n",
    "max_people=5\n",
    "threshold=0.6\n",
    "output_path=\"/output/results/manufacturing/cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonDetect:\n",
    "    '''\n",
    "    Class for the Person Detection Model.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_name, device, threshold=0.60):\n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "        self.threshold=threshold\n",
    "\n",
    "        #try:\n",
    "        self.model=IENetwork(self.model_structure, self.model_weights)\n",
    "        #except Exception as e:\n",
    "        #    raise ValueError(\"Could not Initialise the network. Have you enterred the correct model path?\")\n",
    "\n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IENetwork' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8bde8756d2de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mPersonDetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-dd714f1dc3ed>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, device, threshold)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIENetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#except Exception as e:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#    raise ValueError(\"Could not Initialise the network. Have you enterred the correct model path?\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IENetwork' is not defined"
     ]
    }
   ],
   "source": [
    "pd= PersonDetect(model, device, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
